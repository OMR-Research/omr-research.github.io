<h1>OMR-Research.bib</h1><a name="Pacha2017a"></a><pre>
@inproceedings{<a href="OMR-Research-Year.html#Pacha2017a">Pacha2017a</a>,
  author = {Pacha, Alexander and Eidenberger, Horst},
  title = {Towards Self-Learning Optical Music Recognition},
  booktitle = {2017 16th IEEE International Conference on Machine Learning and Applications (ICMLA)},
  year = {2017},
  pages = {795--800},
  abstract = {Optical Music Recognition (OMR) is a branch of
artificial intelligence that aims at automatically recognizing
and understanding the content of music scores in images.
Several approaches and systems have been proposed that try to
solve this problem by using expert knowledge and specialized
algorithms that tend to fail at generalization to a broader
set of scores, imperfect image scans or data of different
formatting. In this paper we propose a new approach to solve
OMR by investigating how humans read music scores and by
imitating that behavior with machine learning. To demonstrate
the power of this approach, we conduct two experiments
that teach a machine to distinguish entire music sheets from
arbitrary content through frame-by-frame classification and
distinguishing between 32 classes of handwritten music symbols
which can be a basis for object detection. Both tasks can
be performed at high rates of confidence (>98%) which is
comparable to the performance of humans on the same task.},
  doi = {10.1109/ICMLA.2017.00-60},
  file = {:2017 - Towards Self-Learning Optical Music Recognition.pdf:PDF}
}
</pre>

<a name="Pacha2018"></a><pre>
@inproceedings{<a href="OMR-Research-Year.html#Pacha2018">Pacha2018</a>,
  author = {Pacha, Alexander and Choi, Kwon-Young and Co{\"{u}}asnon, Bertrand and Ricquebourg, Yann and Zanibbi, Richard and Eidenberger, Horst},
  title = {Handwritten Music Object Detection: Open Issues and Baseline Results},
  booktitle = {2018 13th IAPR Workshop on Document Analysis Systems (DAS)},
  year = {2018},
  pages = {163--168},
  abstract = {Optical Music Recognition (OMR) is the challenge of understanding the content of musical scores. Accurate detection of individual music objects is a critical step in processing musical documents because a failure at this stage corrupts any further processing. So far, all proposed methods were either limited to typeset music scores or were built to detect only a subset of the available classes of music symbols. In this work, we propose an end-to-end trainable object detector for music symbols that is capable of detecting almost the full vocabulary of modern music notation in handwritten music scores. By training deep convolutional neural networks on the recently released MUSCIMA++ dataset which has symbol-level annotations, we show that a machine learning approach can be used to accurately detect music objects with a mean average precision of over 80%.},
  doi = {10.1109/DAS.2018.51},
  file = {:2018 - Handwritten Music Object Detection - Open Issues and Baseline Results.pdf:PDF},
  keywords = {Optical Music Recognition; Object Detection; Handwritten Scores; Deep Learning}
}
</pre>

<a name="Pacha2018c"></a><pre>
@article{<a href="OMR-Research-Year.html#Pacha2018c">Pacha2018c</a>,
  author = {Pacha, Alexander and Haji{\v{c}}, Jan jr. and Jorge Calvo-Zaragoza},
  title = {A Baseline for General Music Object Detection with Deep Learning},
  journal = {Applied Sciences},
  year = {2018},
  volume = {8},
  number = {9},
  pages = {1488--1508},
  issn = {2076-3417},
  abstract = {Deep learning is bringing breakthroughs to many computer vision subfields including Optical Music Recognition (OMR), which has seen a series of improvements to musical symbol detection achieved by using generic deep learning models. However, so far, each such proposal has been based on a specific dataset and different evaluation criteria, which made it difficult to quantify the new deep learning-based state-of-the-art and assess the relative merits of these detection models on music scores. In this paper, a baseline for general detection of musical symbols with deep learning is presented. We consider three datasets of heterogeneous typology but with the same annotation format, three neural models of different nature, and establish their performance in terms of a common evaluation standard. The experimental results confirm that the direct music object detection with deep learning is indeed promising, but at the same time illustrates some of the domain-specific shortcomings of the general detectors. A qualitative comparison then suggests avenues for OMR improvement, based both on properties of the detection model and how the datasets are defined. To the best of our knowledge, this is the first time that competing music object detection systems from the machine learning paradigm are directly compared to each other. We hope that this work will serve as a reference to measure the progress of future developments of OMR in music object detection.},
  doi = {10.3390/app8091488},
  file = {:2018 - A Baseline for General Music Object Detection with Deep Learning.pdf:PDF},
  keywords = {optical music recognition; deep learning; object detection; music scores},
  url = {<a href="http://www.mdpi.com/2076-3417/8/9/1488">http://www.mdpi.com/2076-3417/8/9/1488</a>}
}
</pre>

<a name="Rebelo2012"></a><pre>
@article{<a href="OMR-Research-Year.html#Rebelo2012">Rebelo2012</a>,
  author = {Rebelo, Ana and Fujinaga, Ichiro and Paszkiewicz, Filipe and Marcal, Andre R.S. and Guedes, Carlos and Cardoso, Jaime S.},
  title = {Optical music recognition: state-of-the-art and open issues},
  journal = {International Journal of Multimedia Information Retrieval},
  year = {2012},
  volume = {1},
  number = {3},
  pages = {173--190},
  doi = {10.1007/s13735-012-0004-6},
  file = {:2012 - Optical Music Recognition - State of the Art and Open Issues.pdf:PDF},
  publisher = {Springer}
}
</pre>

<a name="Rebelo2012a"></a><pre>
@phdthesis{<a href="OMR-Research-Year.html#Rebelo2012a">Rebelo2012a</a>,
  author = {Ana Maria Rebelo},
  title = {Robust Optical Recognition of Handwritten Musical Scores based on Domain Knowledge},
  school = {University of Porto},
  year = {2012},
  institution = {INESC Porto},
  file = {:2012 - Robust Optical Recognition of Handwritten Musical Scores based on Domain Knowledge - Ana Rebelo Phd Thesis.pdf:PDF},
  url = {<a href="http://www.inescporto.pt/~arebelo/arebeloThesis.pdf">http://www.inescporto.pt/~arebelo/arebeloThesis.pdf</a>}
}
</pre>

<a name="Rhodes2016"></a><pre>
@inbook{<a href="OMR-Research-Year.html#Rhodes2016">Rhodes2016</a>,
  pages = {449--459},
  title = {Duplicate Detection in Facsimile Scans of Early Printed Music},
  publisher = {Springer International Publishing},
  year = {2016},
  author = {Rhodes, Christophe and Crawford, Tim and d'Inverno, Mark},
  editor = {Wilhelm, Adalbert F.X. and Kestler, Hans A.},
  address = {Cham},
  isbn = {978-3-319-25226-1},
  abstract = {There is a growing number of collections of readily available scanned
	musical documents, whether generated and managed by libraries, research
	projects, or volunteer efforts. They are typically digital images;
	for computational musicology we also need the musical data in machine-readable
	form. Optical Music Recognition (OMR) can be used on printed music,
	but is prone to error, depending on document condition and the quality
	of intermediate stages in the digitization process such as archival
	photographs. This work addresses the detection of one such error---duplication
	of images---and the discovery of other relationships between images
	in the process.},
  booktitle = {Analysis of Large and Complex Data},
  doi = {10.1007/978-3-319-25226-1_38},
  file = {:2016 - Duplicate detection in facsimile scans of early printed music.pdf:PDF}
}
</pre>

<a name="RISM"></a><pre>
@misc{<a href="OMR-Research-Year.html#RISM">RISM</a>,
  title = {R{\'{e}}pertoire International des Sources Musicales},
  year = {1952},
  url = {<a href="http://www.rism.info">http://www.rism.info</a>}
}
</pre>

<a name="Sampson1985"></a><pre>
@book{<a href="OMR-Research-Year.html#Sampson1985">Sampson1985</a>,
  title = {{W}riting {S}ystems: {A} {L}inguistic {I}ntroduction},
  publisher = {Stanford University Press},
  year = {1985},
  author = {{S}ampson, {G}eoffrey},
  isbn = {9780804717564},
  lccn = {84040708},
  url = {https://books.google.cz/books?id=tVcdNRvwoDkC}
}
</pre>

<a name="Silva2013"></a><pre>
@mastersthesis{<a href="OMR-Research-Year.html#Silva2013">Silva2013</a>,
  author = {{R}ui {M}iguel {F}ilipe da {S}ilva},
  title = {{M}obile framework for recognition of musical characters},
  school = {Universidade do Porto},
  year = {2013},
  file = {:2013 - Mobile framework for recognition of musical characters - Master Thesis.pdf:PDF;:2013 - Mobile Framework for Recognition of Musical Characters - Poster.pdf:PDF},
  url = {https://repositorio-aberto.up.pt/bitstream/10216/68500/2/26777.pdf}
}
</pre>

<a name="Urbano2013"></a><pre>
@techreport{<a href="OMR-Research-Year.html#Urbano2013">Urbano2013</a>,
  author = {Juli\'{a}n Urbano},
  title = {{MIREX 2013 Symbolic Melodic Similarity: A Geometric Model supported with Hybrid Sequence Alignment}},
  institution = {Music Information Retrieval Evaluation eXchange},
  year = {2013},
  file = {:2013 - MIREX 2013 Symbolic Melodic Similarity - A Geometric Model supported with Hybrid Sequence Alignment.pdf:PDF}
}
</pre>

<a name="Wu2017"></a><pre>
@incollection{<a href="OMR-Research-Year.html#Wu2017">Wu2017</a>,
  author = {Fu-Hai Frank Wu},
  title = {Applying Machine Learning in Optical Music Recognition of Numbered Music Notation},
  booktitle = {International Journal of Multimedia Data Engineering and Management (IJMDEM)},
  publisher = {IGI Global},
  year = {2017},
  pages = {21},
  abstract = {Although research of optical music recognition (OMR) has existed for
	few decades, most of efforts were put in step of image processing
	to approach upmost accuracy and evaluations were not in common ground.
	And major music notations explored were the conventional western
	music notations with staff. On contrary, the authors explore the
	challenges of numbered music notation, which is popular in Asia and
	used in daily life for sight reading. The authors use different way
	to improve recognition accuracy by applying elementary image processing
	with rough tuning and supplementing with methods of machine learning.
	The major contributions of this work are the architecture of machine
	learning specified for this task, the dataset, and the evaluation
	metrics, which indicate the performance of OMR system, provide objective
	function for machine learning and highlight the challenges of the
	scores of music with the specified notation.},
  doi = {10.4018/IJMDEM.2017070102}
}
</pre>

<pre>
@comment{{jabref-meta: databaseType:bibtex;}}
</pre>

<pre>
@comment{{jabref-meta: saveActions:enabled;
date[normalize_date]
editor[unicode_to_latex]
pages[normalize_page_numbers]
journal[unicode_to_latex]
author[unicode_to_latex]
all-text-fields[identity]
title[html_to_latex,unicode_to_latex]
booktitle[unicode_to_latex]
;}}
</pre>

<pre>
@comment{{jabref-meta: saveOrderConfig:specified;bibtexkey;false;;false;;false;}}
</pre>

<hr><p><em>This file was generated by
<a href="http://www.lri.fr/~filliatr/bibtex2html/">bibtex2html</a> 1.98.</em></p>
